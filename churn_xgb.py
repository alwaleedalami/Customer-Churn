# -*- coding: utf-8 -*-
"""churn_xgb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JfVzSP0nWwHiJq9QIzfN_43R5J4tIU5B
"""

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score, make_scorer, roc_curve, auc
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from xgboost import XGBClassifier
import tensorflow as tf
import matplotlib.pyplot as plt
import seaborn as sns

data = pd.read_csv('Churn_Modelling.csv')

X = data.drop(columns=['RowNumber', 'CustomerId', 'Surname', 'Exited'])
y = data['Exited']

categorical_cols = X.select_dtypes(include = ['object']).columns
numerical_cols = X.select_dtypes(include = ['int64', 'float64']).columns

for col in numerical_cols:
  plt.figure(figsize = (5, 5))
  sns.histplot(data[col], kde = True, edgecolor = 'black')
  plt.title(f'Distribution of {col}')
  plt.show()

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(), categorical_cols)
    ])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)

X_train_transformed = preprocessor.fit_transform(X_train)
X_test_transformed = preprocessor.transform(X_test)

xgb_classifier = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

param_grid = {
    'n_estimators': [50, 100],
    'learning_rate': [0.1, 0.2],
    'max_depth': [3, 5],
    'subsample': [0.8],
    'colsample_bytree': [0.8],
}

grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, error_score='raise')

try:
    # Fit the grid search to the training data
    grid_search.fit(X_train, y_train)

    # Access the best parameters and estimator if the fit is successful
    best_params = grid_search.best_params_
    print(f"Best Parameters: {best_params}")

    # Train the model with the best hyperparameters
    best_xgb = grid_search.best_estimator_

    # Make predictions on the test set
    y_pred = best_xgb.predict(X_test)

    # Evaluate the model
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)

    print(f"Accuracy: {accuracy}")
    print("Classification Report:")
    print(report)

except Exception as e:
    print(f"An error occurred during grid search: {e}")

